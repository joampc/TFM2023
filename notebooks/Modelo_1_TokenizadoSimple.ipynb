{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joampc/TFM2023/blob/main/notebooks/Modelo_1_TokenizadoSimple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4Z4_-aRliUfJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans==4.0.0-rc1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "id": "XS9AYDUJAsmj",
        "outputId": "ed18b72a-4119-42bb-d5c5-6ee5ed8ae06b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2023.7.22)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17397 sha256=01d06e777c140eaf59f3eca17a4bc137b6d72150e83be1bfe39972612627cfb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 4.0.0\n",
            "    Uninstalling chardet-4.0.0:\n",
            "      Successfully uninstalled chardet-4.0.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "chardet",
                  "idna"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import multiprocessing\n",
        "from functools import partial\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding, RepeatVector\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "import random\n",
        "from googletrans import Translator\n",
        "from scipy.special import softmax\n",
        "\n"
      ],
      "metadata": {
        "id": "e_X8NJGJb5Bh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UCFA_WXCihul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bd6db61-f9e5-4781-d179-46501906808b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hT9D_w3Sidp6",
        "outputId": "df274d1d-4bb8-4a42-dc3e-9417827a41ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de filas: 231637, Número de columnas:12\n"
          ]
        }
      ],
      "source": [
        "df_raw = pd.read_csv('/content/drive/MyDrive/TFM/Dataset Definitivo/RAW_recipes.csv')\n",
        "\n",
        "print(f'Número de filas: {df_raw.shape[0]}, Número de columnas:{df_raw.shape[1]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "X3MstYdiiwHL",
        "outputId": "0166bb34-ef68-47bd-d9c6-9c7ed1fca798"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         name      id  minutes  \\\n",
              "0  arriba   baked winter squash mexican style  137739       55   \n",
              "1            a bit different  breakfast pizza   31490       30   \n",
              "\n",
              "   contributor_id   submitted  \\\n",
              "0           47892  2005-09-16   \n",
              "1           26278  2002-06-17   \n",
              "\n",
              "                                                tags  \\\n",
              "0  ['60-minutes-or-less', 'time-to-make', 'course...   \n",
              "1  ['30-minutes-or-less', 'time-to-make', 'course...   \n",
              "\n",
              "                                   nutrition  n_steps  \\\n",
              "0      [51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]       11   \n",
              "1  [173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]        9   \n",
              "\n",
              "                                               steps  \\\n",
              "0  ['make a choice and proceed with recipe', 'dep...   \n",
              "1  ['preheat oven to 425 degrees f', 'press dough...   \n",
              "\n",
              "                                         description  \\\n",
              "0  autumn is my favorite time of year to cook! th...   \n",
              "1  this recipe calls for the crust to be prebaked...   \n",
              "\n",
              "                                         ingredients  n_ingredients  \n",
              "0  ['winter squash', 'mexican seasoning', 'mixed ...              7  \n",
              "1  ['prepared pizza crust', 'sausage patty', 'egg...              6  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-d1b34bc0-13dc-406c-bbf8-1371efa154b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>id</th>\n",
              "      <th>minutes</th>\n",
              "      <th>contributor_id</th>\n",
              "      <th>submitted</th>\n",
              "      <th>tags</th>\n",
              "      <th>nutrition</th>\n",
              "      <th>n_steps</th>\n",
              "      <th>steps</th>\n",
              "      <th>description</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>n_ingredients</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>arriba   baked winter squash mexican style</td>\n",
              "      <td>137739</td>\n",
              "      <td>55</td>\n",
              "      <td>47892</td>\n",
              "      <td>2005-09-16</td>\n",
              "      <td>['60-minutes-or-less', 'time-to-make', 'course...</td>\n",
              "      <td>[51.5, 0.0, 13.0, 0.0, 2.0, 0.0, 4.0]</td>\n",
              "      <td>11</td>\n",
              "      <td>['make a choice and proceed with recipe', 'dep...</td>\n",
              "      <td>autumn is my favorite time of year to cook! th...</td>\n",
              "      <td>['winter squash', 'mexican seasoning', 'mixed ...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a bit different  breakfast pizza</td>\n",
              "      <td>31490</td>\n",
              "      <td>30</td>\n",
              "      <td>26278</td>\n",
              "      <td>2002-06-17</td>\n",
              "      <td>['30-minutes-or-less', 'time-to-make', 'course...</td>\n",
              "      <td>[173.4, 18.0, 0.0, 17.0, 22.0, 35.0, 1.0]</td>\n",
              "      <td>9</td>\n",
              "      <td>['preheat oven to 425 degrees f', 'press dough...</td>\n",
              "      <td>this recipe calls for the crust to be prebaked...</td>\n",
              "      <td>['prepared pizza crust', 'sausage patty', 'egg...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1b34bc0-13dc-406c-bbf8-1371efa154b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-f2c9cd13-7dbf-40f5-9993-495e8d681e57\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f2c9cd13-7dbf-40f5-9993-495e8d681e57')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-f2c9cd13-7dbf-40f5-9993-495e8d681e57 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d1b34bc0-13dc-406c-bbf8-1371efa154b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d1b34bc0-13dc-406c-bbf8-1371efa154b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "df_raw.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4drBqGUi12B",
        "outputId": "e25f27bf-7026-48c2-eaad-e9ac4dd8441e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    ['winter squash', 'mexican seasoning', 'mixed spice', 'honey', 'butter', 'olive oil', 'salt']\n",
            "1           ['prepared pizza crust', 'sausage patty', 'eggs', 'milk', 'salt and pepper', 'cheese']\n",
            "Name: ingredients, dtype: object\n"
          ]
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(df_raw.loc[:1, 'ingredients'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Variante 1**"
      ],
      "metadata": {
        "id": "v7xv7peaA4_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_rawp = df_raw[:2000]"
      ],
      "metadata": {
        "id": "6Q-pQSNNhm3m"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descarga los recursos necesarios para la tokenización (solo necesitas hacer esto una vez)\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mzIQZfn9e74",
        "outputId": "912dfc51-d931-467c-aa94-82a95301761c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocesamiento de datos"
      ],
      "metadata": {
        "id": "XDr5AFrC7tu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenizacion"
      ],
      "metadata": {
        "id": "lcCoi0jy73BP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Definimos una función para tokenizar una lista de texto (ingredientes o pasos)\n",
        "def tokenize_list(text_list):\n",
        "    # Removemos los corchetes y comillas del texto y luego dividimos por la coma\n",
        "    return [ingredient.lower().strip().strip(\"'\") for ingredient in text_list.strip(\"[]\").split(\",\")]\n",
        "\n",
        "\n",
        "df_rawp['ingredient_tokens'] = df_rawp['ingredients'].apply(tokenize_list)\n",
        "df_rawp['steps_tokens'] = df_rawp['steps'].apply(tokenize_list)\n",
        "\n",
        "\n",
        "# Visualización del DataFrame con las columnas tokenizadas\n",
        "#print(df_raw[['name', 'ingredient_tokens', 'steps_tokens']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHy9MOSC13d8",
        "outputId": "e0a8e985-077c-46ca-af6c-76cb41224f65"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-db03de39da58>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_rawp['ingredient_tokens'] = df_rawp['ingredients'].apply(tokenize_list)\n",
            "<ipython-input-15-db03de39da58>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_rawp['steps_tokens'] = df_rawp['steps'].apply(tokenize_list)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "print(df_rawp.loc[:1, 'ingredients'])\n",
        "print(df_rawp.loc[:1, 'ingredient_tokens'])\n",
        "\n",
        "#df_rawp.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1C-OpXViiYE",
        "outputId": "8868f3c5-1ba2-4e3e-b5d4-b9568f58633a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    ['winter squash', 'mexican seasoning', 'mixed spice', 'honey', 'butter', 'olive oil', 'salt']\n",
            "1           ['prepared pizza crust', 'sausage patty', 'eggs', 'milk', 'salt and pepper', 'cheese']\n",
            "Name: ingredients, dtype: object\n",
            "0    [winter squash, mexican seasoning, mixed spice, honey, butter, olive oil, salt]\n",
            "1         [prepared pizza crust, sausage patty, eggs, milk, salt and pepper, cheese]\n",
            "Name: ingredient_tokens, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_rawp.loc[:1, 'steps'])\n",
        "print(df_rawp.loc[:1, 'steps_tokens'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPXF0wNb4-fN",
        "outputId": "48b71fc8-7cd3-4b85-d10e-c4e182918614"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    ['make a choice and proceed with recipe', 'dep...\n",
            "1    ['preheat oven to 425 degrees f', 'press dough...\n",
            "Name: steps, dtype: object\n",
            "0    [make a choice and proceed with recipe, depend...\n",
            "1    [preheat oven to 425 degrees f, press dough in...\n",
            "Name: steps_tokens, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creación de vocabulario"
      ],
      "metadata": {
        "id": "YewPNExe8Dk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crea un vocabulario a partir de todas las palabras únicas en los ingredientes y pasos. Asigna un índice numérico único a cada palabra para que el modelo pueda trabajar con valores numéricos."
      ],
      "metadata": {
        "id": "9OH6SLwA8Kxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Creación del vocabulario\n",
        "all_texts = df_rawp['ingredient_tokens'].tolist() + df_rawp['steps_tokens'].tolist()\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(all_texts)\n"
      ],
      "metadata": {
        "id": "aTd1RYh95Vkd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creación de secuencias numéricas:\n",
        "\n"
      ],
      "metadata": {
        "id": "gJ2Lckmv8kLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convierte las secuencias de ingredientes y pasos tokenizados en secuencias numéricas utilizando el vocabulario creado. Reemplaza cada palabra en las secuencias con su índice numérico correspondiente."
      ],
      "metadata": {
        "id": "_HDVtl9U8zWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creación de secuencias numéricas\n",
        "ingredient_sequences = tokenizer.texts_to_sequences(df_rawp['ingredient_tokens'])\n",
        "steps_sequences = tokenizer.texts_to_sequences(df_rawp['steps_tokens'])\n"
      ],
      "metadata": {
        "id": "RGHXbsrn5fmG"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Padding"
      ],
      "metadata": {
        "id": "1GvilVo_874e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Asegúrate de que todas las secuencias de ingredientes y pasos tengan la misma longitud. Esto es necesario para poder alimentar los datos al modelo en lotes.\n",
        "Agrega tokens de relleno al final de las secuencias más cortas para que todas tengan la misma longitud máxima."
      ],
      "metadata": {
        "id": "AIqcZjFD89jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding\n",
        "max_sequence_length = max(max(len(seq) for seq in ingredient_sequences), max(len(seq) for seq in steps_sequences))\n",
        "ingredient_sequences = pad_sequences(ingredient_sequences, maxlen=max_sequence_length, padding='post')\n",
        "steps_sequences = pad_sequences(steps_sequences, maxlen=max_sequence_length, padding='post')"
      ],
      "metadata": {
        "id": "NtZe4P4w5kXV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##División de datos:"
      ],
      "metadata": {
        "id": "v3oxvC899OIm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separa los datos en conjuntos de entrenamiento, validación y prueba. Es común usar aproximadamente un 80% de los datos para entrenamiento, un 10% para validación y un 10% para pruebas."
      ],
      "metadata": {
        "id": "EZ5fq9ml9UVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# División de datos en conjuntos de entrenamiento, validación y prueba\n",
        "\n",
        "train_size = int(0.8 * len(df_raw))\n",
        "val_size = int(0.1 * len(df_raw))\n",
        "train_ingredients = ingredient_sequences[:train_size]\n",
        "train_steps = steps_sequences[:train_size]\n",
        "val_ingredients = ingredient_sequences[train_size:train_size+val_size]\n",
        "val_steps = steps_sequences[train_size:train_size+val_size]\n",
        "test_ingredients = ingredient_sequences[train_size+val_size:]\n",
        "test_steps = steps_sequences[train_size+val_size:]\n",
        "\n",
        "\n",
        "# También puedes obtener el vocabulario creado por el Tokenizer y los índices de palabras utilizando:\n",
        "word_index = tokenizer.word_index\n"
      ],
      "metadata": {
        "id": "05N1II4E9YRG"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Modelo"
      ],
      "metadata": {
        "id": "o5uGCmSE93An"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Construcción del modelo:"
      ],
      "metadata": {
        "id": "ZvpHhy_i97xn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Comprobaciones que hicieron falta hasta q logre que funcionara\n",
        "\n",
        "# Verificar las formas de los datos de entrenamiento y etiquetas\n",
        "print(\"Forma de train_ingredients:\", train_ingredients.shape)\n",
        "print(\"Forma de train_steps:\", train_steps.shape)\n",
        "\n",
        "# Verificar los tipos de datos\n",
        "print(\"Tipo de train_ingredients:\", train_ingredients.dtype)\n",
        "print(\"Tipo de train_steps:\", train_steps.dtype)\n",
        "\n",
        "# Verificar la longitud máxima de las secuencias de ingredientes y pasos\n",
        "print(\"Longitud máxima de secuencias de ingredientes:\", train_ingredients.shape[1])\n",
        "print(\"Longitud máxima de secuencias de pasos:\", train_steps.shape[1])\n",
        "\n",
        "# Verificar el vocabulario y las etiquetas\n",
        "vocab_size = len(word_index) + 1\n",
        "print(\"Tamaño del vocabulario:\", vocab_size)\n",
        "\n",
        "# Imprime algunas etiquetas para verificar que sean enteros y estén en el rango correcto\n",
        "print(\"Etiquetas de entrenamiento:\", train_steps[:10])\n",
        "\n",
        "\n",
        "#La forma de train_ingredients es (1000, 85), lo que significa que tienes 1000 ejemplos de recetas,\n",
        "#cada una representada por una secuencia de ingredientes con una longitud máxima de 85 palabras.\n",
        "#La forma de train_steps es también (1000, 85), lo que indica que tienes 1000 ejemplos de recetas,\n",
        "# cada una representada por una secuencia de pasos con una longitud máxima de 85 palabras.\n",
        "#Ambos arrays tienen el tipo de dato int32, que es el tipo de dato adecuado para datos de enteros.\n",
        "#La longitud máxima de secuencias para ingredientes y pasos es 85, lo que significa que todas las recetas\n",
        "# han sido acotadas a esta longitud máxima. Si algunas recetas tenían más de 85 palabras,\n",
        "#se truncaron para que todas las secuencias tengan la misma longitud.\n",
        "\n",
        "#El tamaño del vocabulario es 13794, lo que significa que hay 13794 palabras únicas en tus datos."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "truBSaoW_mUP",
        "outputId": "8b4018b0-ce2c-4bae-b1ad-e1e084bb5670"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de train_ingredients: (2000, 149)\n",
            "Forma de train_steps: (2000, 149)\n",
            "Tipo de train_ingredients: int32\n",
            "Tipo de train_steps: int32\n",
            "Longitud máxima de secuencias de ingredientes: 149\n",
            "Longitud máxima de secuencias de pasos: 149\n",
            "Tamaño del vocabulario: 25539\n",
            "Etiquetas de entrenamiento: [[3904 3905 3906 ...    0    0    0]\n",
            " [1306 3923 3924 ...    0    0    0]\n",
            " [3931 3932 1307 ...    0    0    0]\n",
            " ...\n",
            " [3960 3961 3962 ...    0    0    0]\n",
            " [3975 3976 3977 ...    0    0    0]\n",
            " [  78 3985 3986 ...    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este código se encarga de crear y entrenar un modelo codificador-decodificador para generar recetas a partir de ingredientes. Explicaré cada paso en detalle:\n",
        "\n",
        "1. **Creación del vocabulario:**\n",
        "   - Se obtiene la lista completa de tokens de ingredientes y pasos de todas las recetas.\n",
        "   - Se crea un `Tokenizer`, que se utiliza para transformar el texto en secuencias de números enteros y construir el vocabulario basado en la frecuencia de las palabras.\n",
        "   - El método `fit_on_texts` del `Tokenizer` se utiliza para ajustar el vocabulario en función de todas las secuencias de texto proporcionadas.\n",
        "\n",
        "2. **Verificación de tokens especiales:**\n",
        "   - Se verifica si los tokens especiales '<start>' y '<end>' están presentes en el vocabulario. Estos tokens se utilizan para marcar el inicio y el final de las secuencias de texto generadas. Si no están presentes, se agregan manualmente al vocabulario.\n",
        "\n",
        "3. **Obtención del tamaño del vocabulario:**\n",
        "   - Se obtiene el tamaño del vocabulario que se utilizará en la capa de incrustación del modelo.\n",
        "\n",
        "4. **Preprocesamiento de los datos:**\n",
        "   - Se asegura de que la longitud máxima de ingredientes y pasos sea la misma para que puedan combinarse adecuadamente durante el entrenamiento.\n",
        "   - Rellena las secuencias de ingredientes y pasos con ceros para que tengan la misma longitud máxima.\n",
        "\n",
        "5. **Definición del modelo codificador-decodificador:**\n",
        "   - Se define la arquitectura del modelo codificador-decodificador utilizando la API funcional de Keras.\n",
        "   - El modelo utiliza dos capas LSTM (codificador y decodificador) para procesar secuencias de texto y generar recetas.\n",
        "   - Se utilizan capas de incrustación para aprender representaciones vectoriales de palabras.\n",
        "   - La última capa es una capa densa con una activación softmax para generar las probabilidades de la siguiente palabra en la secuencia.\n",
        "\n",
        "6. **Compilación del modelo:**\n",
        "   - Se compila el modelo utilizando el optimizador 'adam' y la función de pérdida 'sparse_categorical_crossentropy'. El modelo se evaluará en función de la precisión (accuracy) durante el entrenamiento.\n",
        "\n",
        "7. **Ajuste de la forma de train_steps_padded:**\n",
        "   - Se ajusta la forma de `train_steps_padded` para que pueda utilizarse adecuadamente en el entrenamiento. Se agrega una columna de ceros al final de cada secuencia.\n",
        "\n",
        "8. **Entrenamiento del modelo:**\n",
        "   - Se entrena el modelo utilizando los ingredientes (`train_ingredients_padded`) como entrada y los pasos de las recetas (`train_steps_padded[:, :-1]`) como salida esperada. El objetivo es predecir la siguiente palabra en la secuencia de pasos.\n",
        "   - El modelo se entrena durante 50 épocas con un tamaño de lote de 32.\n",
        "\n",
        "En resumen, este código crea y entrena un modelo de generación de recetas utilizando una arquitectura codificador-decodificador con capas LSTM y una capa densa de salida con activación softmax. El modelo se entrena para predecir la siguiente palabra en la secuencia de pasos de recetas a partir de los ingredientes proporcionados.\n",
        "\n",
        "===============================================================================\n",
        "\n",
        "En el contexto del modelo codificador-decodificador que se está utilizando para generar recetas, las capas de incrustación se refieren a las capas de Embedding en Keras. La incrustación (embedding en inglés) es un proceso mediante el cual se transforman las palabras en vectores numéricos densos y continuos, de modo que las palabras con significados similares se representen por vectores cercanos en un espacio vectorial.\n",
        "\n",
        "En el código proporcionado, se utilizan dos capas de incrustación:\n",
        "\n",
        "encoder_embedding: Esta capa de incrustación se aplica a la secuencia de ingredientes (encoder_input) para aprender representaciones vectoriales de las palabras en los ingredientes. Esto se hace para que el modelo pueda entender mejor la relación entre los ingredientes y los pasos de la receta.\n",
        "decoder_embedding: Esta capa de incrustación se aplica a la secuencia de pasos (decoder_input) para aprender representaciones vectoriales de las palabras en los pasos de la receta. Esto es esencial para que el modelo pueda generar pasos coherentes y significativos en la receta.\n",
        "Las capas de incrustación aprenden los vectores de palabras durante el proceso de entrenamiento del modelo codificador-decodificador. Cada palabra en el vocabulario se asigna a un vector numérico que se actualiza iterativamente a medida que el modelo se ajusta a los datos de entrenamiento. Al final del entrenamiento, el modelo ha aprendido representaciones vectoriales que reflejan las relaciones semánticas y sintácticas entre las palabras del vocabulario. Estas representaciones incrustadas permiten al modelo generar recetas coherentes y relevantes basadas en los ingredientes proporcionados.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Regenerate"
      ],
      "metadata": {
        "id": "vKZVP_VSTCKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, LSTM, Dense\n",
        "import numpy as np\n",
        "\n",
        "# Creación del vocabulario\n",
        "all_texts = df_rawp['ingredient_tokens'].tolist() + df_rawp['steps_tokens'].tolist()\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(all_texts)\n",
        "\n",
        "# Verificar si '<start>' y '<end>' están presentes en el vocabulario, si no, agrégales manualmente\n",
        "if '<start>' not in tokenizer.word_index:\n",
        "    tokenizer.word_index['<start>'] = len(tokenizer.word_index) + 1\n",
        "    tokenizer.index_word[len(tokenizer.word_index)] = '<start>'\n",
        "\n",
        "if '<end>' not in tokenizer.word_index:\n",
        "    tokenizer.word_index['<end>'] = len(tokenizer.word_index) + 1\n",
        "    tokenizer.index_word[len(tokenizer.word_index)] = '<end>'\n",
        "\n",
        "# Obtener el tamaño del vocabulario del tokenizer\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Asegurar que la longitud máxima de ingredientes y pasos sea la misma\n",
        "max_sequence_length = 85\n",
        "\n",
        "# Rellenar secuencias con ceros para que todas tengan la misma longitud\n",
        "train_ingredients_padded = pad_sequences(train_ingredients, maxlen=max_sequence_length, padding='post')\n",
        "train_steps_padded = pad_sequences(train_steps, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "# Definir la arquitectura del modelo codificador-decodificador\n",
        "embedding_dim = 100\n",
        "rnn_units = 128\n",
        "\n",
        "encoder_input = Input(shape=(max_sequence_length,))\n",
        "encoder_embedding = Embedding(vocab_size, embedding_dim)(encoder_input)\n",
        "encoder_lstm = LSTM(rnn_units)(encoder_embedding)\n",
        "\n",
        "decoder_input = Input(shape=(max_sequence_length,))\n",
        "decoder_embedding = Embedding(vocab_size, embedding_dim)(decoder_input)\n",
        "decoder_lstm = LSTM(rnn_units, return_sequences=True)(decoder_embedding)\n",
        "decoder_output = Dense(vocab_size, activation='softmax')(decoder_lstm)\n",
        "\n",
        "# Crear el modelo codificador-decodificador\n",
        "model = Model([encoder_input, decoder_input], decoder_output)\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Ajustar la forma de train_steps_padded\n",
        "train_steps_padded = np.pad(train_steps_padded, [(0, 0), (0, 1)], mode='constant', constant_values=0)\n",
        "\n",
        "# Entrenar el modelo con más épocas (por ejemplo, 50 épocas)\n",
        "model.fit([train_ingredients_padded, train_steps_padded[:, :-1]], train_steps_padded[:, 1:], epochs=50, batch_size=32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDrFUDNtcbqM",
        "outputId": "9eca1b68-38a7-4a7b-b67f-9faabd443a0f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "63/63 [==============================] - 201s 3s/step - loss: 4.1633 - accuracy: 0.9827\n",
            "Epoch 2/50\n",
            "63/63 [==============================] - 192s 3s/step - loss: 0.1234 - accuracy: 0.9986\n",
            "Epoch 3/50\n",
            "63/63 [==============================] - 199s 3s/step - loss: 0.0769 - accuracy: 0.9986\n",
            "Epoch 4/50\n",
            "63/63 [==============================] - 190s 3s/step - loss: 0.0516 - accuracy: 0.9986\n",
            "Epoch 5/50\n",
            "63/63 [==============================] - 188s 3s/step - loss: 0.0309 - accuracy: 0.9986\n",
            "Epoch 6/50\n",
            "63/63 [==============================] - 197s 3s/step - loss: 0.0244 - accuracy: 0.9987\n",
            "Epoch 7/50\n",
            "63/63 [==============================] - 190s 3s/step - loss: 0.0206 - accuracy: 0.9986\n",
            "Epoch 8/50\n",
            "63/63 [==============================] - 191s 3s/step - loss: 0.0177 - accuracy: 0.9987\n",
            "Epoch 9/50\n",
            "63/63 [==============================] - 197s 3s/step - loss: 0.0165 - accuracy: 0.9987\n",
            "Epoch 10/50\n",
            "63/63 [==============================] - 188s 3s/step - loss: 0.0186 - accuracy: 0.9987\n",
            "Epoch 11/50\n",
            "63/63 [==============================] - 190s 3s/step - loss: 0.0185 - accuracy: 0.9987\n",
            "Epoch 12/50\n",
            "63/63 [==============================] - 188s 3s/step - loss: 0.0155 - accuracy: 0.9987\n",
            "Epoch 13/50\n",
            "63/63 [==============================] - 190s 3s/step - loss: 0.0158 - accuracy: 0.9987\n",
            "Epoch 14/50\n",
            "63/63 [==============================] - 189s 3s/step - loss: 0.0167 - accuracy: 0.9987\n",
            "Epoch 15/50\n",
            "63/63 [==============================] - 189s 3s/step - loss: 0.0168 - accuracy: 0.9987\n",
            "Epoch 16/50\n",
            "63/63 [==============================] - 190s 3s/step - loss: 0.0159 - accuracy: 0.9987\n",
            "Epoch 17/50\n",
            "63/63 [==============================] - 190s 3s/step - loss: 0.0156 - accuracy: 0.9987\n",
            "Epoch 18/50\n",
            "63/63 [==============================] - 190s 3s/step - loss: 0.0153 - accuracy: 0.9987\n",
            "Epoch 19/50\n",
            "63/63 [==============================] - 191s 3s/step - loss: 0.0156 - accuracy: 0.9987\n",
            "Epoch 20/50\n",
            "63/63 [==============================] - 206s 3s/step - loss: 0.0149 - accuracy: 0.9987\n",
            "Epoch 21/50\n",
            "63/63 [==============================] - 211s 3s/step - loss: 0.0150 - accuracy: 0.9987\n",
            "Epoch 22/50\n",
            "63/63 [==============================] - 192s 3s/step - loss: 0.0139 - accuracy: 0.9987\n",
            "Epoch 23/50\n",
            "63/63 [==============================] - 190s 3s/step - loss: 0.0144 - accuracy: 0.9987\n",
            "Epoch 24/50\n",
            "63/63 [==============================] - 193s 3s/step - loss: 0.0139 - accuracy: 0.9987\n",
            "Epoch 25/50\n",
            "63/63 [==============================] - 200s 3s/step - loss: 0.0136 - accuracy: 0.9987\n",
            "Epoch 26/50\n",
            "63/63 [==============================] - 205s 3s/step - loss: 0.0138 - accuracy: 0.9987\n",
            "Epoch 27/50\n",
            "63/63 [==============================] - 206s 3s/step - loss: 0.0134 - accuracy: 0.9987\n",
            "Epoch 28/50\n",
            "63/63 [==============================] - 207s 3s/step - loss: 0.0132 - accuracy: 0.9987\n",
            "Epoch 29/50\n",
            "63/63 [==============================] - 204s 3s/step - loss: 0.0137 - accuracy: 0.9987\n",
            "Epoch 30/50\n",
            "63/63 [==============================] - 197s 3s/step - loss: 0.0131 - accuracy: 0.9987\n",
            "Epoch 31/50\n",
            "63/63 [==============================] - 190s 3s/step - loss: 0.0132 - accuracy: 0.9987\n",
            "Epoch 32/50\n",
            "63/63 [==============================] - 194s 3s/step - loss: 0.0129 - accuracy: 0.9987\n",
            "Epoch 33/50\n",
            "63/63 [==============================] - 211s 3s/step - loss: 0.0128 - accuracy: 0.9987\n",
            "Epoch 34/50\n",
            "63/63 [==============================] - 204s 3s/step - loss: 0.0126 - accuracy: 0.9987\n",
            "Epoch 35/50\n",
            "63/63 [==============================] - 204s 3s/step - loss: 0.0130 - accuracy: 0.9987\n",
            "Epoch 36/50\n",
            "63/63 [==============================] - 197s 3s/step - loss: 0.0126 - accuracy: 0.9987\n",
            "Epoch 37/50\n",
            "63/63 [==============================] - 201s 3s/step - loss: 0.0125 - accuracy: 0.9987\n",
            "Epoch 38/50\n",
            "63/63 [==============================] - 192s 3s/step - loss: 0.0122 - accuracy: 0.9987\n",
            "Epoch 39/50\n",
            "63/63 [==============================] - 201s 3s/step - loss: 0.0122 - accuracy: 0.9987\n",
            "Epoch 40/50\n",
            "63/63 [==============================] - 206s 3s/step - loss: 0.0119 - accuracy: 0.9987\n",
            "Epoch 41/50\n",
            "63/63 [==============================] - 207s 3s/step - loss: 0.0117 - accuracy: 0.9987\n",
            "Epoch 42/50\n",
            "63/63 [==============================] - 209s 3s/step - loss: 0.0115 - accuracy: 0.9987\n",
            "Epoch 43/50\n",
            "63/63 [==============================] - 203s 3s/step - loss: 0.0113 - accuracy: 0.9987\n",
            "Epoch 44/50\n",
            "63/63 [==============================] - 207s 3s/step - loss: 0.0111 - accuracy: 0.9987\n",
            "Epoch 45/50\n",
            "63/63 [==============================] - 208s 3s/step - loss: 0.0110 - accuracy: 0.9987\n",
            "Epoch 46/50\n",
            "63/63 [==============================] - 209s 3s/step - loss: 0.0108 - accuracy: 0.9987\n",
            "Epoch 47/50\n",
            "63/63 [==============================] - 203s 3s/step - loss: 0.0135 - accuracy: 0.9986\n",
            "Epoch 48/50\n",
            "63/63 [==============================] - 205s 3s/step - loss: 0.0107 - accuracy: 0.9987\n",
            "Epoch 49/50\n",
            "63/63 [==============================] - 209s 3s/step - loss: 0.0104 - accuracy: 0.9987\n",
            "Epoch 50/50\n",
            "63/63 [==============================] - 202s 3s/step - loss: 0.0102 - accuracy: 0.9987\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7b596e9047f0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Uso del modelo para generar una receta\n"
      ],
      "metadata": {
        "id": "7h9otZmdSxd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# para poder imprimir en párrafos\n",
        "!pip install textwrap3\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tq3ShxZpNKtW",
        "outputId": "79d90da7-5831-4836-aae7-73cc9d15083e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textwrap3\n",
            "  Downloading textwrap3-0.9.2-py2.py3-none-any.whl (12 kB)\n",
            "Installing collected packages: textwrap3\n",
            "Successfully installed textwrap3-0.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import textwrap\n",
        "\n",
        "\n",
        "def softmax(x, temperature=1.0):\n",
        "    e_x = np.exp((x - np.max(x)) / temperature)\n",
        "    return e_x / e_x.sum(axis=0)\n",
        "\n",
        "def generate_recipe_from_ingredients(model, tokenizer, ingredients_list, max_recipe_length=85, end_token='<end>', temperature=0.8):\n",
        "    start_token = '<start>'\n",
        "    step_sequence = [tokenizer.word_index[start_token]]\n",
        "\n",
        "    # Convertir los ingredientes a secuencias numéricas utilizando el tokenizer\n",
        "    ingredients_sequence = tokenizer.texts_to_sequences([ingredients_list])\n",
        "    initial_ingredients_list = pad_sequences(ingredients_sequence, maxlen=max_recipe_length, padding='post')\n",
        "\n",
        "    # Generar los pasos de la receta\n",
        "    for _ in range(max_recipe_length - 1):\n",
        "        step_sequence_input = pad_sequences([step_sequence], maxlen=max_recipe_length, padding='post', truncating='post')\n",
        "        next_token_probs = model.predict([initial_ingredients_list, step_sequence_input])[0, len(step_sequence) - 1]\n",
        "\n",
        "        # Utilizar temperatura para suavizar la distribución de probabilidad\n",
        "        next_token_probs = softmax(next_token_probs, temperature=temperature)\n",
        "        next_token_index = np.random.choice(len(next_token_probs), p=next_token_probs)\n",
        "\n",
        "        # Verificar que el índice generado esté dentro del rango válido del vocabulario\n",
        "        while next_token_index == 0 or tokenizer.index_word.get(next_token_index) is None:\n",
        "            next_token_index = np.random.choice(len(next_token_probs), p=next_token_probs)\n",
        "\n",
        "        next_token = tokenizer.index_word[next_token_index]\n",
        "        step_sequence.append(next_token_index)\n",
        "\n",
        "        if next_token == end_token:\n",
        "            break\n",
        "\n",
        "    # Convertir los índices de las palabras a texto\n",
        "    recipe_text = ' '.join(tokenizer.index_word[idx] for idx in step_sequence[1:])  # Excluir el token de inicio\n",
        "    return recipe_text\n",
        "\n",
        "# Utilizando la función para generar una receta a partir de una lista de ingredientes\n",
        "ingredients_list = ['fish', 'onion', 'garlic', 'potatoes']\n",
        "recipe = generate_recipe_from_ingredients(model, tokenizer, ingredients_list)\n",
        "\n",
        "\n",
        "\n",
        "#print(\"Receta generada:\", recipe)\n",
        "\n",
        "# Imprimir la receta con wordwrap\n",
        "print(\"\\nReceta generada:\")\n",
        "wrapper = textwrap.TextWrapper(width=80)\n",
        "lines = wrapper.wrap(recipe)\n",
        "for line in lines:\n",
        "    print(line)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGaXx8Bve_kd",
        "outputId": "b8d6e6b1-f7ed-4516-be31-9f2fe6947100"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 549ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "1/1 [==============================] - 0s 148ms/step\n",
            "1/1 [==============================] - 0s 144ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "1/1 [==============================] - 0s 163ms/step\n",
            "1/1 [==============================] - 0s 181ms/step\n",
            "1/1 [==============================] - 0s 153ms/step\n",
            "1/1 [==============================] - 0s 158ms/step\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "1/1 [==============================] - 0s 155ms/step\n",
            "1/1 [==============================] - 0s 278ms/step\n",
            "1/1 [==============================] - 0s 192ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 186ms/step\n",
            "1/1 [==============================] - 0s 159ms/step\n",
            "1/1 [==============================] - 0s 147ms/step\n",
            "1/1 [==============================] - 0s 137ms/step\n",
            "1/1 [==============================] - 0s 197ms/step\n",
            "1/1 [==============================] - 0s 144ms/step\n",
            "1/1 [==============================] - 0s 150ms/step\n",
            "1/1 [==============================] - 0s 178ms/step\n",
            "1/1 [==============================] - 0s 234ms/step\n",
            "1/1 [==============================] - 0s 205ms/step\n",
            "1/1 [==============================] - 0s 175ms/step\n",
            "1/1 [==============================] - 0s 140ms/step\n",
            "1/1 [==============================] - 0s 155ms/step\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "1/1 [==============================] - 0s 142ms/step\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "1/1 [==============================] - 0s 104ms/step\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "1/1 [==============================] - 0s 145ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 125ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "1/1 [==============================] - 0s 156ms/step\n",
            "\n",
            "Receta generada:\n",
            "place on cookie sheet \"add the corn / oat mixture to the remaining egg whites\n",
            "after 7 days mix in the flour and salt - kneading is unnecessary you will end up\n",
            "with a big multi-layered cake or sandwich of omelettes ! store in tupperware\n",
            "until ready to cook \"shape the loaves by turning the dough under it's self over\n",
            "and over\" frozen broccoli cuts slowly add the brown sugar and granulated white\n",
            "sugar flatten with a glass or cookie stamp roma tomatoes place on a baking sheet\n",
            "and let rise for 1 hour then bake for 10 minutes allowing it to flow down and\n",
            "cover the sides mix the dressing ingredients together with a wire whisk this is\n",
            "great for a crock pot \"don't use store bought powder place 1 scoop chocolate ice\n",
            "cream next and add generous scoop of marshmallow creme strawberry: omit peanut\n",
            "butter and add 1 1 / 2 cups frozen strawberries at the initial blending salt and\n",
            "tapioca in small bowl and then sprinkle over all the meat and veggies sprinkle\n",
            "flour over melted butter and whisk together to form a paste spray top with no-\n",
            "stick cooking spray season with the pepper and salt add the rest of the sauce\n",
            "ingredients scrub potatoes and cut into 1 / 2 inch cubes reduce heat and simmer\n",
            "for 1-1 1 / 2 hours sprinkle with fleur-de-sel and serve with desired sides sour\n",
            "cream and tortilla chips vanilla extract and oil and until well blended while\n",
            "still in bag remaining mousse cream of spinach soup mix pour into prepared pan\n",
            "noodles: in a large stockpot place the fish in a baking dish just large enough\n",
            "to hold them heat oven to 325f beat at medium speed until blended basically\n",
            "using a cake knife or smooth spatula fold the dry ingredients into the wet oil\n",
            "needs to be hot enough to melt the brown sugar inside the sandwiches but not so\n",
            "hot that it scorches the batter cool in pan 15 minutes celery and onions may\n",
            "also be added to the crockpot while the roast cooks pound each strip -inch thick\n",
            "dissolve in yeast stirring occasionally until softened sift in the remaining\n",
            "flour and mix until smooth combine flour and sugar in a large bowl in a large\n",
            "dutch oven with a tight fitting lid add ground beef repeat layers ending with\n",
            "sauce continue to stir this roux over medium heat for two to three minutes line\n",
            "an 8-by-8-inch glass baking dish with aluminum foil cover while resting tzatziki\n",
            "stir and cook 5 minutes until golden and unwrap the dough pour the potato / egg\n",
            "mixture into it cook about 2 to 3 minutes until garlic is softened add chocolate\n",
            "deglaze with sherry and simmer until evaporated covering the pan then 1 slice\n",
            "each of the cheeses on top of each burger if you weigh 100 pounds then drink 50\n",
            "ounces of water sure-jell press \"start\" the can of beans and corn\" season with\n",
            "salt and pepper to taste and drizzle with a small amount of lemon juice \"add to\n",
            "the roast's pan drippings: the boiling water 1 / 2 fat stir in flour until well\n",
            "blended gently stir in cool whip topping about 25 minutes for rolls for\n",
            "vegetarian use the vegetable broth pour coconut milk powder into this mixture\n",
            "and mix thoroughly and quickly mix water are bubbly cook about 2-3 minutes per\n",
            "side flour tortillas to make 1 batch of muffins measure out 2 cups of dry mix\n",
            "place cut side up in each of 2 greased 9 inch round cake pans empty the spinach\n",
            "into a colander and drain pour everything except for the cheese into a blender\n",
            "mix remaining ingredients well in a bowl and pour over fish manicotti\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#para mostrar los ingredientes y recetas en español\n",
        "translator = Translator()\n",
        "\n",
        "def translate_to_spanish(text):\n",
        "    translation = translator.translate(text, src='en', dest='es')\n",
        "    return translation.text\n"
      ],
      "metadata": {
        "id": "V8S2dAbtAhTl"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generación de la receta:\n",
        "\n",
        "La función comienza inicializando una secuencia de pasos de receta step_sequence con el token especial <start>, que indica el inicio de una receta.\n",
        "Convierte los tokens de ingredientes seleccionados a secuencias numéricas utilizando el tokenizer proporcionado.\n",
        "Establece la longitud máxima de la receta (max_recipe_length) como el mínimo entre max_steps y la longitud de la secuencia de ingredientes seleccionados más uno (para tener en cuenta el token especial <start>).\n",
        "Luego, rellena o trunca la secuencia de ingredientes seleccionados para que tenga la misma longitud que max_recipe_length.\n",
        "El bucle for se encarga de generar los pasos de la receta. En cada iteración:\n",
        "Se rellena o trunca la secuencia de pasos de receta (step_sequence_input) para que tenga la misma longitud que max_recipe_length.\n",
        "Se obtienen las probabilidades de las siguientes palabras en la secuencia de pasos utilizando el modelo entrenado (model.predict).\n",
        "Se utiliza una temperatura para suavizar la distribución de probabilidad y generar un índice de palabra aleatorio.\n",
        "Se verifica que el índice generado esté dentro del rango válido del vocabulario.\n",
        "Se agrega la siguiente palabra a la secuencia de pasos (step_sequence).\n",
        "Si la siguiente palabra es el token especial <end>, se detiene la generación de la receta.\n",
        "Finalmente, la secuencia de pasos de receta se convierte en texto utilizando el tokenizer.\n",
        "\n",
        "**MAX LENGHT**\n",
        "La idea principal detrás de max_recipe_length es controlar la longitud de la receta generada. Para ello, se considera la longitud de random_tokens_sequence, que representa los ingredientes seleccionados. La receta generada debe comenzar con un token especial <start> y luego continuar con los pasos generados. Por lo tanto, la longitud máxima de la receta se establece como el mínimo entre max_steps (el número máximo de pasos permitidos) y la longitud de random_tokens_sequence más uno (para tener en cuenta el token especial <start> al principio de la receta).\n",
        "\n",
        "\n",
        "**TEMPERATURA**\n",
        "La temperatura es un parámetro importante en el proceso de generación de texto utilizando modelos de lenguaje como el que estamos utilizando aquí. En general, se utiliza para controlar la aleatoriedad y diversidad de las predicciones generadas por el modelo.\n",
        "\n",
        "Cuando se genera texto con un modelo de lenguaje, el modelo produce distribuciones de probabilidad para cada palabra en el vocabulario en función del contexto actual. La probabilidad de cada palabra indica la \"confianza\" del modelo en que esa palabra sea la siguiente en la secuencia de texto.\n",
        "\n",
        "Una temperatura alta (por ejemplo, 1.0) hace que la distribución de probabilidad sea más uniforme, lo que significa que las predicciones son más aleatorias y diversas. En otras palabras, el modelo tiene más libertad para seleccionar palabras menos probables y generar resultados más creativos pero también menos precisos.\n",
        "\n",
        "Por otro lado, una temperatura baja (por ejemplo, 0.1) hace que la distribución de probabilidad sea más puntiaguda, lo que significa que las predicciones son más deterministas y se inclinan hacia las palabras más probables. En este caso, el modelo tiende a ser más conservador y genera resultados más precisos pero menos sorprendentes.\n",
        "\n",
        "En resumen, una temperatura alta da lugar a predicciones más aleatorias y diversas, mientras que una temperatura baja da lugar a predicciones más precisas y deterministas. La elección de la temperatura depende del resultado deseado: si se busca creatividad e innovación, una temperatura alta puede ser adecuada, mientras que si se busca coherencia y precisión, una temperatura baja puede ser preferible. Generalmente, valores alrededor de 0.5 a 1.0 se utilizan para mayor diversidad y valores alrededor de 0.1 a 0.5 para mayor precisión."
      ],
      "metadata": {
        "id": "oIW1xyVvVPR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**En esta función generate_recipe_from_random_ingredients, se generan los pasos de la receta utilizando el modelo codificador-decodificador, pero los pasos se agregan uno por uno en cada iteración del bucle. Esto no garantiza que los 5 ingredientes aleatorios seleccionados se utilicen en la receta generada**"
      ],
      "metadata": {
        "id": "F4j4CJp8ZHWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "\n",
        "translator = Translator()\n",
        "\n",
        "def translate_to_spanish(text):\n",
        "    translation = translator.translate(text, src='en', dest='es')\n",
        "    return translation.text\n",
        "\n",
        "\n",
        "def generate_recipe_from_random_ingredients(model, tokenizer, df, num_ingredients=5, max_steps=10, end_token='<end>', temperature=0.8):\n",
        "    # Obtener la lista completa de tokens de ingredientes\n",
        "    all_ingredients = df['ingredient_tokens'].tolist()\n",
        "    all_tokens = [token for ingredients in all_ingredients for token in ingredients]\n",
        "\n",
        "    # Seleccionar 5 tokens aleatorios\n",
        "    random_tokens = random.sample(all_tokens, num_ingredients)\n",
        "\n",
        "    print(\"Ingredientes seleccionados:\")\n",
        "    for i, token in enumerate(random_tokens):\n",
        "        english_ingredient = token\n",
        "        spanish_ingredient = translate_to_spanish(token)\n",
        "        print(f\"Ingrediente {i+1}: {english_ingredient} / {spanish_ingredient}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    start_token = '<start>'\n",
        "    step_sequence = [tokenizer.word_index[start_token]]\n",
        "\n",
        "    # Convertir los tokens seleccionados a secuencias numéricas utilizando el tokenizer\n",
        "    random_tokens_sequence = tokenizer.texts_to_sequences([random_tokens])[0]\n",
        "\n",
        "    # Encontrar la receta más larga entre las seleccionadas y usarla como longitud máxima\n",
        "    max_recipe_length = min(max_steps, len(random_tokens_sequence) + 1)\n",
        "\n",
        "    # Rellenar o truncar la secuencia de ingredientes para que tenga la misma longitud que max_recipe_length\n",
        "    initial_ingredients_list = pad_sequences([random_tokens_sequence], maxlen=max_recipe_length - 1, padding='post', truncating='post')\n",
        "\n",
        "    # Generar los pasos de la receta\n",
        "    for _ in range(max_steps - 1):\n",
        "        step_sequence_input = pad_sequences([step_sequence], maxlen=max_recipe_length, padding='post', truncating='post')\n",
        "        next_token_probs = model.predict([initial_ingredients_list, step_sequence_input])[0, len(step_sequence_input[0]) - 1]\n",
        "\n",
        "        # Utilizar temperatura para suavizar la distribución de probabilidad\n",
        "        next_token_probs = softmax(next_token_probs, temperature=temperature)\n",
        "        next_token_index = np.random.choice(len(next_token_probs), p=next_token_probs)\n",
        "\n",
        "        # Verificar que el índice generado esté dentro del rango válido del vocabulario\n",
        "        while next_token_index == 0 or tokenizer.index_word.get(next_token_index) is None:\n",
        "            next_token_index = np.random.choice(len(next_token_probs), p=next_token_probs)\n",
        "\n",
        "        next_token = tokenizer.index_word[next_token_index]\n",
        "        step_sequence.append(next_token_index)\n",
        "\n",
        "        if next_token == end_token:\n",
        "            break\n",
        "\n",
        "    # Convertir los índices de las palabras a texto, excluyendo el token de inicio\n",
        "    recipe_text = ' '.join(tokenizer.index_word.get(idx, '') for idx in step_sequence[1:])\n",
        "\n",
        "      # Convertir los índices de las palabras a texto, excluyendo el token de inicio, y traducir a español\n",
        "    recipe_sp = ' '.join(translate_to_spanish(tokenizer.index_word.get(idx, '')) for idx in step_sequence[1:])\n",
        "\n",
        "    return recipe_text, recipe_sp\n",
        "\n",
        "# Utilizando la función para generar una receta con 5 ingredientes aleatorios\n",
        "recipe, recipe_sp = generate_recipe_from_random_ingredients(model, tokenizer, df_rawp, num_ingredients=5, max_steps=8, temperature=0.1)\n",
        "# Imprimir la receta con wordwrap\n",
        "print(\"\\nReceta generada:\")\n",
        "wrapper = textwrap.TextWrapper(width=80)\n",
        "lines = wrapper.wrap(recipe)\n",
        "for line in lines:\n",
        "    print(line)\n",
        "print('\\n')\n",
        "lines_sp = wrapper.wrap(recipe_sp)\n",
        "for line in lines_sp:\n",
        "    print(line)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUWl2W4VwKoh",
        "outputId": "a81158c1-4714-4643-f60a-85f4a2017666"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingredientes seleccionados:\n",
            "Ingrediente 1: sugar / azúcar\n",
            "Ingrediente 2: flour / harina\n",
            "Ingrediente 3: water / agua\n",
            "Ingrediente 4: ground coriander / cilantro\n",
            "Ingrediente 5: hot sauce / salsa picante\n",
            "1/1 [==============================] - 0s 448ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "\n",
            "Receta generada:\n",
            "3 tablespoons brown sugar and 15 caramels until smooth mix the melted caramels\n",
            "with the icing sugar and 3 tablespoons milk with an electric mixer until smooth\n",
            "when edges begin to bubble and lift from skillet crisco shortening as soon as\n",
            "the leavening ingredients are combined if it appears dry and stiff or if you\n",
            "machine sounds as if it's straining to knead it buy the long box not the country\n",
            "layer 5: celery\n",
            "\n",
            "\n",
            "3 cucharadas de azúcar morena y 15 caramelos hasta que mezcle suave los\n",
            "caramelos derretidos con el azúcar glas y 3 cucharadas de leche con una batidora\n",
            "eléctrica hasta que estén suaves Cuando los bordes comienzan a burbujear y\n",
            "levantar de la sartén acortamiento de crisco Tan pronto como se combinan los\n",
            "ingredientes de la levadura Si parece seco y rígido o si la máquina suena como\n",
            "si se esforzara por amasarlo Compre la caja larga, no el país Capa 5: apio\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import textwrap\n",
        "from googletrans import Translator\n",
        "\n",
        "translator = Translator()\n",
        "\n",
        "def translate_to_spanish(text):\n",
        "    translation = translator.translate(text, src='en', dest='es')\n",
        "    return translation.text\n",
        "\n",
        "def generate_recipe_from_random_ingredients(model, tokenizer, df, num_ingredients=5, max_steps=10, end_token='<end>', temperature=0.8):\n",
        "    # Obtener la lista completa de tokens de ingredientes\n",
        "    all_ingredients = df['ingredient_tokens'].tolist()\n",
        "    all_tokens = [token for ingredients in all_ingredients for token in ingredients]\n",
        "\n",
        "    # Seleccionar 5 tokens aleatorios\n",
        "    random_tokens = random.sample(all_tokens, num_ingredients)\n",
        "\n",
        "    print(\"Ingredientes seleccionados:\")\n",
        "    for i, token in enumerate(random_tokens):\n",
        "        english_ingredient = token\n",
        "        spanish_ingredient = translate_to_spanish(token)\n",
        "        print(f\"Ingrediente {i+1}: {english_ingredient} / {spanish_ingredient}\")\n",
        "\n",
        "    # Convertir los tokens seleccionados a secuencias numéricas utilizando el tokenizer\n",
        "    random_tokens_sequence = tokenizer.texts_to_sequences([random_tokens])[0]\n",
        "\n",
        "    # Encontrar la receta más larga entre las seleccionadas y usarla como longitud máxima\n",
        "    max_recipe_length = min(max_steps, len(random_tokens_sequence) + 1)\n",
        "\n",
        "    # Rellenar o truncar la secuencia de ingredientes para que tenga la misma longitud que max_recipe_length\n",
        "    initial_ingredients_list = pad_sequences([random_tokens_sequence], maxlen=max_recipe_length - 1, padding='post', truncating='post')\n",
        "\n",
        "    # Generar los pasos de la receta\n",
        "    step_sequence = [tokenizer.word_index['<start>']] + list(random_tokens_sequence)\n",
        "    for _ in range(max_steps - 1):\n",
        "        step_sequence_input = pad_sequences([step_sequence], maxlen=max_recipe_length, padding='post', truncating='post')\n",
        "        next_token_probs = model.predict([initial_ingredients_list, step_sequence_input])[0, len(step_sequence_input[0]) - 1]\n",
        "\n",
        "        # Utilizar temperatura para suavizar la distribución de probabilidad\n",
        "        next_token_probs = softmax(next_token_probs, temperature=temperature)\n",
        "        next_token_index = np.random.choice(len(next_token_probs), p=next_token_probs)\n",
        "\n",
        "        # Verificar que el índice generado esté dentro del rango válido del vocabulario\n",
        "        while next_token_index == 0 or tokenizer.index_word.get(next_token_index) is None:\n",
        "            next_token_index = np.random.choice(len(next_token_probs), p=next_token_probs)\n",
        "\n",
        "        next_token = tokenizer.index_word[next_token_index]\n",
        "        step_sequence.append(next_token_index)\n",
        "\n",
        "        if next_token == end_token:\n",
        "            break\n",
        "\n",
        "    # Convertir los índices de las palabras a texto, excluyendo el token de inicio\n",
        "    recipe_text = ' '.join(tokenizer.index_word.get(idx, '') for idx in step_sequence[1:])\n",
        "\n",
        "    # Convertir los índices de las palabras a texto, excluyendo el token de inicio, y traducir a español\n",
        "    recipe_sp = ' '.join(translate_to_spanish(tokenizer.index_word.get(idx, '')) for idx in step_sequence[1:])\n",
        "\n",
        "    return recipe_text, recipe_sp\n",
        "\n",
        "# Utilizando la función para generar una receta con 5 ingredientes aleatorios\n",
        "recipe, recipe_sp = generate_recipe_from_random_ingredients(model, tokenizer, df_rawp, num_ingredients=5, max_steps=10, temperature=0.5)\n",
        "# Imprimir la receta con wordwrap\n",
        "print(\"\\nReceta generada:\")\n",
        "wrapper = textwrap.TextWrapper(width=80)\n",
        "lines = wrapper.wrap(recipe)\n",
        "for line in lines:\n",
        "    print(line)\n",
        "print('\\n')\n",
        "lines_sp = wrapper.wrap(recipe_sp)\n",
        "for line in lines_sp:\n",
        "    print(line)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2lOc8f2XAe0",
        "outputId": "dc92c2f1-44f7-4ea0-94ec-3b4a058d77ab"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingredientes seleccionados:\n",
            "Ingrediente 1: boiling water / agua hirviendo\n",
            "Ingrediente 2: tomato paste / pasta de tomate\n",
            "Ingrediente 3: parmesan cheese / queso parmesano\n",
            "Ingrediente 4: sugar / azúcar\n",
            "Ingrediente 5: clove / Clavo\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "\n",
            "Receta generada:\n",
            "boiling water tomato paste parmesan cheese sugar clove to freeze: allow soup to\n",
            "cool put the green peas on top of the spinach or mixed greens refrigerate for\n",
            "about 10 to 15 minutes before cutting into 2 inch squares set aside 1 / 2 cup to\n",
            "1 cup of the greens sausage mixture for the top \"some folks like to serve this\n",
            "hot instead of cold: bake at 350 degrees f for 30 minutes stir until\n",
            "marshmallows are all melted in a large dutch oven with a tight fitting lid these\n",
            "are so easy and goes great with salsa flip [carefully] when you see bubbles in\n",
            "the middle of the pancake\n",
            "\n",
            "\n",
            "agua hirviendo pasta de tomate queso parmesano azúcar Clavo Para congelar: deja\n",
            "que la sopa se enfríe Pon los guisantes verdes encima de las espinacas o\n",
            "verduras mixtas Refrigere durante unos 10 a 15 minutos antes de cortar cuadrados\n",
            "de 2 pulgadas Ponga a un lado 1/2 taza a 1 taza de la mezcla de salchicha de\n",
            "verduras para la parte superior \"A algunas personas les gusta servir este frío\n",
            "en lugar de frío: hornear a 350 grados F durante 30 minutos Revuelva hasta que\n",
            "los malvaviscos estén derretidos En un gran horno holandés con una tapa ajustada\n",
            "Estos son tan fáciles y van muy bien con la salsa Voltee [cuidadosamente] cuando\n",
            "vea burbujas en el medio del panqueque\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def translate_to_spanish(text):\n",
        "    translation = translator.translate(text, src='en', dest='es')\n",
        "    return translation.text\n",
        "\n",
        "\n",
        "def generate_recipe_from_random_ingredients(model, tokenizer, df, num_ingredients=5, max_steps=12, end_token='<end>', temperature=0.5):\n",
        "    # Obtener la lista completa de tokens de ingredientes\n",
        "    all_ingredients = df['ingredient_tokens'].tolist()\n",
        "    all_tokens = [token for ingredients in all_ingredients for token in ingredients]\n",
        "\n",
        "    # Seleccionar 5 tokens aleatorios\n",
        "    random_tokens = random.sample(all_tokens, num_ingredients)\n",
        "\n",
        "    print(\"Ingredientes seleccionados:\")\n",
        "    for i, token in enumerate(random_tokens):\n",
        "        english_ingredient = token\n",
        "        spanish_ingredient = translate_to_spanish(token)\n",
        "        print(f\"Ingrediente {i+1}: {english_ingredient} / {spanish_ingredient}\")\n",
        "\n",
        "    # Convertir los tokens seleccionados a secuencias numéricas utilizando el tokenizer\n",
        "    random_tokens_sequence = tokenizer.texts_to_sequences([random_tokens])[0]\n",
        "\n",
        "    # Encontrar la receta más larga entre las seleccionadas y usarla como longitud máxima\n",
        "    max_recipe_length = min(max_steps, len(random_tokens_sequence) + 1)\n",
        "\n",
        "    # Rellenar o truncar la secuencia de ingredientes para que tenga la misma longitud que max_recipe_length\n",
        "    initial_ingredients_list = pad_sequences([random_tokens_sequence], maxlen=max_recipe_length - 1, padding='post', truncating='post')\n",
        "\n",
        "    # Generar los pasos de la receta\n",
        "    step_sequence = [tokenizer.word_index['<start>']] + list(random_tokens_sequence)\n",
        "    for _ in range(max_steps - num_ingredients - 1):\n",
        "        step_sequence_input = pad_sequences([step_sequence], maxlen=max_recipe_length, padding='post', truncating='post')\n",
        "        next_token_probs = model.predict([initial_ingredients_list, step_sequence_input])[0, len(step_sequence_input[0]) - 1]\n",
        "\n",
        "        # Utilizar temperatura para suavizar la distribución de probabilidad\n",
        "        next_token_probs = softmax(next_token_probs, temperature=temperature)\n",
        "        next_token_index = np.random.choice(len(next_token_probs), p=next_token_probs)\n",
        "\n",
        "        # Verificar que el índice generado esté dentro del rango válido del vocabulario\n",
        "        while next_token_index == 0 or tokenizer.index_word.get(next_token_index) is None:\n",
        "            next_token_index = np.random.choice(len(next_token_probs), p=next_token_probs)\n",
        "\n",
        "        next_token = tokenizer.index_word[next_token_index]\n",
        "        step_sequence.append(next_token_index)\n",
        "\n",
        "        if next_token == end_token:\n",
        "            break\n",
        "\n",
        "    # Convertir los índices de las palabras a texto, excluyendo el token de inicio\n",
        "    recipe_text = ' '.join(tokenizer.index_word.get(idx, '') for idx in step_sequence[1:])\n",
        "\n",
        "    # Convertir los índices de las palabras a texto, excluyendo el token de inicio, y traducir a español\n",
        "    recipe_sp = ' '.join(translate_to_spanish(tokenizer.index_word.get(idx, '')) for idx in step_sequence[1:])\n",
        "\n",
        "    return recipe_text, recipe_sp\n",
        "\n",
        "\n",
        "# Utilizando la función para generar una receta con 5 ingredientes aleatorios\n",
        "recipe, recipe_sp = generate_recipe_from_random_ingredients(model, tokenizer, df_rawp, num_ingredients=5, max_steps=12, temperature=0.5)\n",
        "# Imprimir la receta con wordwrap\n",
        "print(\"\\nReceta generada:\")\n",
        "wrapper = textwrap.TextWrapper(width=80)\n",
        "lines = wrapper.wrap(recipe)\n",
        "for line in lines:\n",
        "    print(line)\n",
        "print('\\n')\n",
        "lines_sp = wrapper.wrap(recipe_sp)\n",
        "for line in lines_sp:\n",
        "    print(line)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiqN5CcPxbKJ",
        "outputId": "e5cf4f17-9092-44a6-c33e-c6a6d02ea5c9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingredientes seleccionados:\n",
            "Ingrediente 1: frozen chopped spinach / espinacas picadas congeladas\n",
            "Ingrediente 2: flour / harina\n",
            "Ingrediente 3: cream of mushroom soup / crema de sopa de hongos\n",
            "Ingrediente 4: lean ground beef / carne de res molida\n",
            "Ingrediente 5: semi-sweet chocolate chips / chips de chocolate semidulce\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "\n",
            "Receta generada:\n",
            "frozen chopped spinach flour cream of mushroom soup lean ground beef semi-sweet\n",
            "chocolate chips saute onions until they are clear and soft add the pumpkin and\n",
            "all the remaining ingredients except the last 2 and bring to a simmer knead for\n",
            "6-8 minutes add flour alternating with 7-up currants half and slice your apple\n",
            "\n",
            "\n",
            "espinacas picadas congeladas harina crema de sopa de hongos carne de res molida\n",
            "chips de chocolate semidulce saltee las cebollas hasta que estén claras y suaves\n",
            "Agregue la calabaza y todos los ingredientes restantes, excepto los últimos 2 y\n",
            "llevar a fuego lento amasar durante 6-8 minutos Agregue harina alternando con\n",
            "7-up grosellas mitad y corta tu manzana\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_recipe_from_random_ingredients(model, tokenizer, df, num_ingredients=5, max_steps=12, end_token='<end>', temperature=0.5):\n",
        "    # Obtener la lista completa de tokens de ingredientes\n",
        "    all_ingredients = df['ingredient_tokens'].tolist()\n",
        "    all_tokens = [token for ingredients in all_ingredients for token in ingredients]\n",
        "\n",
        "    # Seleccionar 5 tokens aleatorios\n",
        "    random_tokens = random.sample(all_tokens, num_ingredients)\n",
        "\n",
        "    print(\"Ingredientes seleccionados:\")\n",
        "    for i, token in enumerate(random_tokens):\n",
        "        english_ingredient = token\n",
        "        spanish_ingredient = translate_to_spanish(token)\n",
        "        print(f\"Ingrediente {i+1}: {english_ingredient} / {spanish_ingredient}\")\n",
        "\n",
        "    # Convertir los tokens seleccionados a secuencias numéricas utilizando el tokenizer\n",
        "    random_tokens_sequence = tokenizer.texts_to_sequences([random_tokens])[0]\n",
        "\n",
        "    # Rellenar o truncar la secuencia de ingredientes para que tenga la misma longitud que max_steps\n",
        "    initial_ingredients_list = pad_sequences([random_tokens_sequence], maxlen=max_steps - 1, padding='post', truncating='post')\n",
        "\n",
        "    # Generar los pasos de la receta\n",
        "    step_sequence = [tokenizer.word_index['<start>']]\n",
        "    for _ in range(max_steps - num_ingredients - 1):\n",
        "        step_sequence_input = pad_sequences([step_sequence], maxlen=max_steps, padding='post', truncating='post')\n",
        "        next_token_probs = model.predict([initial_ingredients_list, step_sequence_input])[0, len(step_sequence)]\n",
        "\n",
        "        # Utilizar temperatura para suavizar la distribución de probabilidad\n",
        "        next_token_probs = softmax(next_token_probs, temperature=temperature)\n",
        "        # Normalizar las probabilidades para que sumen 1\n",
        "        next_token_probs /= next_token_probs.sum()\n",
        "\n",
        "        # Muestrear el siguiente token utilizando las probabilidades normalizadas\n",
        "        next_token_index = np.random.choice(len(next_token_probs), p=next_token_probs)\n",
        "\n",
        "        # Verificar que el índice generado esté dentro del rango válido del vocabulario\n",
        "        while next_token_index == 0 or tokenizer.index_word.get(next_token_index) is None:\n",
        "            next_token_index = np.random.choice(len(next_token_probs), p=next_token_probs)\n",
        "\n",
        "        next_token = tokenizer.index_word[next_token_index]\n",
        "        step_sequence.append(next_token_index)\n",
        "\n",
        "        if next_token == end_token:\n",
        "            break\n",
        "\n",
        "    # Agregar los ingredientes seleccionados a los pasos de la receta generada\n",
        "    for i, token_idx in enumerate(random_tokens_sequence):\n",
        "        step_sequence.insert(i+1, token_idx)\n",
        "\n",
        "    # Convertir los índices de las palabras a texto, excluyendo el token de inicio\n",
        "    recipe_text = ' '.join(tokenizer.index_word.get(idx, '') for idx in step_sequence[1:])\n",
        "\n",
        "    # Convertir los índices de las palabras a texto, excluyendo el token de inicio, y traducir a español\n",
        "    recipe_sp = ' '.join(translate_to_spanish(tokenizer.index_word.get(idx, '')) for idx in step_sequence[1:])\n",
        "\n",
        "    return recipe_text, recipe_sp\n",
        "\n",
        "\n",
        "# Utilizando la función para generar una receta con 5 ingredientes aleatorios\n",
        "recipe, recipe_sp = generate_recipe_from_random_ingredients(model, tokenizer, df_rawp, num_ingredients=5, max_steps=12, temperature=0.5)\n",
        "# Imprimir la receta con wordwrap\n",
        "print(\"\\nReceta generada:\")\n",
        "wrapper = textwrap.TextWrapper(width=80)\n",
        "lines = wrapper.wrap(recipe)\n",
        "for line in lines:\n",
        "    print(line)\n",
        "print('\\n')\n",
        "lines_sp = wrapper.wrap(recipe_sp)\n",
        "for line in lines_sp:\n",
        "    print(line)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjtTSnVsPsrC",
        "outputId": "f64e4fc2-4b21-4aec-e167-457e129399e9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingredientes seleccionados:\n",
            "Ingrediente 1: banana / banana\n",
            "Ingrediente 2: tomatoes / Tomates\n",
            "Ingrediente 3: black beans / frijoles negros\n",
            "Ingrediente 4: condensed french onion soup / sopa de cebolla francesa condensada\n",
            "Ingrediente 5: salt / sal\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "\n",
            "Receta generada:\n",
            "banana tomatoes black beans condensed french onion soup salt mix everything\n",
            "except asparagus and set aside leave it in the mixer drain and return meat\n",
            "mixture to skillet break up the brittle in small pieces and place into a food\n",
            "processor stir in flour until well blended but not boiling\n",
            "\n",
            "\n",
            "banana Tomates frijoles negros sopa de cebolla francesa condensada sal Mezclar\n",
            "todo excepto los espárragos y reservar Déjalo en la batidora Drene y regrese la\n",
            "mezcla de carne a la sartén Rompe el quebradiza en trozos pequeños y colóquelo\n",
            "en un procesador de alimentos Agregue la harina hasta que esté bien mezclado\n",
            "pero no hirviendo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "au4NZstvX6wN"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}